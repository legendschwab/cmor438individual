{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_Networks:\n",
    "    def __init__(self, layer_sizes, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        layer_sizes: list of sizes like [input_size, h1, h2, ..., output_size]\n",
    "        \"\"\"\n",
    "        self.lr = learning_rate\n",
    "        self.num_layers = len(layer_sizes) - 1\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        for i in range(self.num_layers):\n",
    "            # in_size gives number of inputs at layer_i, out_size gives number of outputs after layer_i\n",
    "            in_size = layer_sizes[i]\n",
    "            out_size = layer_sizes[i+1]\n",
    "            # Initialize weights according to the Kaiming He initialization rule\n",
    "            self.weights.append(np.random.randn(in_size, out_size) * np.sqrt(2. / in_size))\n",
    "            self.biases.append(np.zeros((1, out_size)))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_deriv(self, x):\n",
    "        s = self.sigmoid(x)\n",
    "        return s * (1 - s)\n",
    "       \n",
    "    def forward(self, X):\n",
    "        self.zs = []  # Linear outputs\n",
    "        self.activations = [X]  # Store inputs and activations\n",
    "        a = X\n",
    "        for i in range(self.num_layers - 1):  # Hidden layers\n",
    "            z = a @ self.weights[i] + self.biases[i]\n",
    "            a = self.sigmoid(z)\n",
    "            self.zs.append(z)\n",
    "            self.activations.append(a)\n",
    "        # Output layer \n",
    "        z = a @ self.weights[-1] + self.biases[-1]\n",
    "        self.zs.append(z)\n",
    "        self.activations.append(z)\n",
    "        return z\n",
    "\n",
    "    def backward(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        grads_w = [None] * self.num_layers\n",
    "        grads_b = [None] * self.num_layers\n",
    "\n",
    "        # Output layer gradients (MSE loss)\n",
    "        delta = (y_pred - y_true) / m\n",
    "        grads_w[-1] = self.activations[-2].T @ delta\n",
    "        grads_b[-1] = np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "        # Hidden layers (backpropagation)\n",
    "        for i in reversed(range(self.num_layers - 1)):\n",
    "            delta = (delta @ self.weights[i+1].T) * self.sigmoid_deriv(self.zs[i])\n",
    "            grads_w[i] = self.activations[i].T @ delta\n",
    "            grads_b[i] = np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        for i in range(self.num_layers):\n",
    "            self.weights[i] -= self.lr * grads_w[i]\n",
    "            self.biases[i] -= self.lr * grads_b[i]\n",
    "\n",
    "    def train(self, X, y, epochs=1000, verbose=True):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = np.mean((y - y_pred) ** 2)\n",
    "            self.backward(y, y_pred)\n",
    "            if verbose and epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Application to Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in Data Set and Cleaning\n",
    "game_data = pd.read_csv(\"../bgg_dataset.csv\",delimiter=\";\")\n",
    "\n",
    "game_data['Complexity Average'] = game_data['Complexity Average'].str.replace(',', '.').astype(float)\n",
    "game_data['Rating Average'] = game_data['Rating Average'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Selecting Columns of Top 100 Games\n",
    "game_cleaned = game_data[['Rating Average','Complexity Average','Min Age','Play Time','BGG Rank']]\n",
    "game_cleaned = game_cleaned[game_cleaned['BGG Rank'] <= 100]\n",
    "game_cleaned.dropna(inplace = True)\n",
    "\n",
    "# Labelling short games as those where play time is less than or equal to 60 minutes\n",
    "game_cleaned['short'] = np.where(game_cleaned['Play Time'] <= 60, 1, 0)\n",
    "\n",
    "short = game_cleaned[game_cleaned['short'] == 1]\n",
    "long = game_cleaned[game_cleaned['short'] == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ```'Rating Average'```, ```'Complexity Average'```, and ```'Min Age'``` to predict whether the game is short or long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xh/x976_5p93059y1sn4ybh8ql40000gn/T/ipykernel_43526/1556016909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 3. Define and fit the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeural_Networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 4. Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xh/x976_5p93059y1sn4ybh8ql40000gn/T/ipykernel_43526/1139636085.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}, Loss: {loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xh/x976_5p93059y1sn4ybh8ql40000gn/T/ipykernel_43526/1139636085.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Hidden layers (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mgrads_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mgrads_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 80)"
     ]
    }
   ],
   "source": [
    "# Preparing data \n",
    "X = game_cleaned[['Rating Average', 'Complexity Average','Min Age']].to_numpy()\n",
    "y = game_cleaned['short'].to_numpy()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Scale the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Define and fit the neural network\n",
    "model = Neural_Networks(layer_sizes = [3, 2, 1])\n",
    "model.train(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
